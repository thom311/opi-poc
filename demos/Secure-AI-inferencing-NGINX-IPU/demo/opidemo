#!/usr/bin/env bash

NGINX_IP="172.16.3.200"

_OPI_BASH_X=()
if [[ $- == *x* ]] ; then
    _OPI_BASH_X=( "-x" )
fi

C_RED=''
C_GREEN=''
C_BLUE=''
C_YELLOW=''
C_RESET=''
C_BG_BRIGHT_CYAN=''
if [ -t 1 ] ; then
    if [ "${#_OPI_BASH_X[@]}" -eq 0 ] || [ "$_FORCE_COLOR" = 1 ] ; then
        C_RED=$'\033[1;31m'
        C_GREEN=$'\033[1;32m'
        C_BLUE=$'\033[1;34m'
        C_YELLOW=$'\033[1;33m'
        C_RESET=$'\033[0m'
        C_BG_BRIGHT_CYAN=$'\033[106m'
    fi
fi

_OPI_SSH_T=()
if [ -t 1 ] ; then
    _OPI_SSH_T=( "-t" "-o" "LogLevel=ERROR" )
fi

_quote() {
    (
        set +x
        case "$#" in
            0)
                ;;
            1)
                printf '%q' "$1"
                ;;
            *)
                printf '%q' "$1"
                shift
                printf ' %q' "$@"
                ;;
        esac
    ) 2>/dev/null
}

_echo_n() {
    printf '%s' "$*"
}

_echo() {
    printf '%s\n' "$*"
}

_echo_p() {
    local ts=""

    if [ "$_SHOW_TIMESTAMP" = 1 ] ; then
        ts="[$(date +"%H:%M:%S.%3N")]"
    fi

    printf '%s%s%s\n' "${C_YELLOW}demo$ts>${C_RESET} " "$_ECHO_P_INDENT" "$*"
}

die() {
    _echo "$C_RED$*$C_RESET"
    exit 1
}

_yq_pretty() {
    if [ -n "$_OPIDEMO_YQ_BINARY" ] ; then
        "$_OPIDEMO_YQ_BINARY" -P
    else
        cat
    fi
}

_indent() {
    local level="$1"

    sed "s/^/$(printf '%*s' "$level" "")/"
}

_unindent() {
    local level="${1:-0}"

    sed "s/^$(printf '%*s' "$level" "")//"
}

_generate_file() {
    local filename="$1"
    local unindent_level="${2:-12}"
    local executable="$3"

    _unindent "$unindent_level" > "$filename"

    if [ -z "$executable" ] ; then
        if head -n1 "$filename" | grep -q '^#!' ; then
            executable='executable'
        else
            executable='regular'
        fi
    fi

    case "$executable" in
        executable)
            chmod +x "$filename"
            ;;
        regular)
            ;;
        *)
            die "wrong executable $executable"
            ;;
    esac
}

# shellcheck disable=SC2120
_generate_notes() {
    local unindent_level="${1:-12}"

    (
        cat <<EOF | _unindent 12
            NOTES ($(basename "$PWD"))
            ==================================

EOF
        cat | _unindent "$unindent_level"
    ) \
        | _generate_file '0.notes.md' "0" "regular"
}

_generate_bash() {
    local filename="$1"
    local unindent_level="${2:-12}"

    (
        cat <<'        EOF' | _unindent 12
            #!/bin/bash

            cd "$(dirname "$0")"
            export PS4=$'\n\033[1;37;44m>>>\033[0m '
            set -x

        EOF
        cat | _unindent "$unindent_level"
    ) \
        | _generate_file "$filename" "0" "executable"
}

usage() {
    local SCRIPTNAME="$SCRIPTNAME"
    local SCRIPTNAME_PRETTY="${SCRIPTNAME_PRETTY:-$SCRIPTNAME}"
    local commands

    mapfile -t commands < <(sed -n '/^    case "''$''main_cmd" in/,/    esac$/ s/^        \([a-zA-Z_0-9]\+\).*/\1/p' "$SCRIPTNAME")

    _echo "Usage $C_GREEN$SCRIPTNAME_PRETTY$C_RESET COMMAND..."
    _echo
    _echo "Inspect the script or run with \`bash -x\` to see what the shell script does."
    _echo "You may source the script and call the shell functions directly."
    _echo

    local config
    local configs
    mapfile -t configs < <(sed -n '/USER CONFIGURATION/,/^$/ s/^\([A-Za-z0-9_]\+\).*/\1/p' "$SCRIPTNAME")

    for config in "${configs[@]}" ; do
        _echo "  export $C_BLUE$config$C_RESET=${!config}"
    done

    _echo

    # Parse the shell script itself, to get out the available commands and
    # doc string.
    ${PYTHON:-python3} -c 'if 1:
        import os, sys, re

        _, scriptname, c_yellow, c_green, c_reset, *commands = sys.argv

        with open(scriptname, "r") as f:
            script_reversed = f.readlines()
        script_reversed.reverse()
        script_reversed = [s.rstrip("\n") for s in script_reversed]

        def _find_cmd_idx(cmd):
            return next(i for i, line in enumerate(script_reversed) if re.match(f"^(do_)?{cmd}\\(", line))

        def _find_cmd_doc(cmd):
            lst = []
            idx = _find_cmd_idx(cmd) + 1
            while script_reversed[idx].startswith("#"):
                lst.append(re.sub("^# ?", "", script_reversed[idx]))
                idx += 1
            lst.reverse()
            return lst

        def _parse(cmd):
            mode, synopsis, *doc = _find_cmd_doc(cmd)
            mode, prio = mode.rsplit(":", 1)
            mode_prio, mode = mode.split(":", 1)
            return {
                "cmd": cmd,
                "mode": mode,
                "synopsis": synopsis,
                "mode_prio": int(mode_prio),
                "prio": int(prio),
                "doc": doc,
            }

        docs = [_parse(c) for c in commands]
        docs.sort(key=lambda v: (v["mode_prio"], v["prio"]))

        last_mode = ""
        for doc in docs:
            cmd, mode, synopsis, doc = doc["cmd"], doc["mode"], doc["synopsis"], doc["doc"]
            if last_mode != mode:
                last_mode = mode
                print(f"{c_yellow}{last_mode}{c_reset} operations:")
            if synopsis:
                synopsis = f" {synopsis}"
            print(f"  {c_green}{cmd}{c_reset}{synopsis}")
            print("".join(f"    {s}\n" for s in doc), end="")
    ' \
        "$SCRIPTNAME" \
        "$C_YELLOW" \
        "$C_GREEN" \
        "$C_RESET" \
        "${commands[@]}"
}

_find_kubeconfig() {
    local kc

    for kc in "$PWD/"kubeconfig* /root/kubeconfig*; do
        if [ -f "$kc" ] ; then
            _echo "$kc"
            return 0
        fi
    done

    _echo "/root/kubeconfig.ocpcluster"
}

_oc() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"
    local oc_verbose="$oc_verbose"

    local argv
    local argv2=()
    local argv3=()

    if [ "$oc_verbose" = 1 ] ; then
        _echo_n "> $C_BLUE"
        _quote 'oc' "$@"
        _echo "$C_RESET"
    fi

    argv=( oc "--kubeconfig=$KUBECONFIG" "$@" )

    if [ "$OC_REMOTE" = 1 ] ; then
        mapfile -t argv2 < <( _quote "${argv[@]}" )
        mapfile -t argv3 < <( _quote "${argv2[@]}" )
        argv=( ssh "root@$PROV_HOST" bash -c "${argv3[@]}" )
    fi

    "${argv[@]}" || return $?
    return 0
}

is_prov_host() {
    local PROV_HOST="$PROV_HOST"

    if [ "$FORCE_IS_PROV_HOST" = 1 ] ; then
        return 0
    fi

    local rc=0

    if [ -n "$PROV_HOST" ] && \
       [ "$(ssh "root@$PROV_HOST" cat /proc/sys/kernel/random/boot_id)" != "$(cat /proc/sys/kernel/random/boot_id)" ] ; then
        rc=1
    fi

    # Update the function itself with a memoized value. Let's only
    # detect once.
    eval "is_prov_host() { return $rc ; }"
    return $rc
}

_exec() {
    local host
    local _EXEC_SILENT="$_EXEC_SILENT"
    local _EXEC_NOTTY="$_EXEC_NOTTY"
    local PROV_HOST="$PROV_HOST"

    while : ; do
        case "$1" in
            -s)
                local _EXEC_SILENT=1
                shift
                ;;
            -T)
                local _EXEC_NOTTY=1
                shift
                ;;
            *)
                break
                ;;
        esac
    done

    host="$1"

    [ -n "$host" ] || die "missing name of target host for exec"

    shift

    local args=()
    local args_cmd

    if [ "$#" -gt 0 ] ; then
        args=( "$@" )
    else
        args=( bash )
    fi

    args_cmd="$(printf '%q ' "${args[@]}")"
    args_cmd="${args_cmd% }"

    if [ "$_EXEC_SILENT" != 1 ] ; then
        _echo_p "Run on $host: $args_cmd"
    fi

    local _ssh_t=()
    local _oc_t=()
    if [ "$_EXEC_NOTTY" != 1 ] ; then
        _ssh_t=( "${_OPI_SSH_T[@]}" )
        if [ "${#_OPI_SSH_T[@]}" -gt 0 ] ; then
            _oc_t=( '-t' )
        fi
    fi

    local ssh_cmd_prov_host=()
    if ! is_prov_host ; then
        # If we are not on tgen1, we progably will first remote the call via
        # ssh. that has two reasons:
        # - some hosts (dh4-acc) are not directly accessible via the SSH. We
        #   Need to go through tgen1
        # - by going through tgen1, we only need authentication via that host.
        #   tgen1 can from there password-less login to the other hosts.
        ssh_cmd_prov_host=( ssh "${_ssh_t[@]}" "root@$PROV_HOST" )
    fi

    case "$host" in
        localhost)
            ssh_cmd_prov_host=()
            ;;
        prov_host)
            if [ "${#ssh_cmd_prov_host[@]}" -gt 0 ] ; then
                args=( "${ssh_cmd_prov_host[@]}" "$args_cmd" )
            fi
            ssh_cmd_prov_host=()
            ;;
        *)
            die "Invalid host $host for exec"
            ;;
    esac

    if [ "${#ssh_cmd_prov_host[@]}" -gt 0 ] ; then
        local cmd2

        cmd2="$(printf '%q ' "${args[@]}")"
        cmd2="${cmd2% }"
        args=( "${ssh_cmd_prov_host[@]}" "$cmd2" )
    fi

    (
        cd "$ORIGINAL_PWD"

        if [ "$_EXEC_CMDSILENT" = 1 ] ; then
            "${args[@]}" &>/dev/null < /dev/stdin
        else
            "${args[@]}" < /dev/stdin
        fi
    )
}

###############################################################################

call_remote() {
    local PROV_HOST="$PROV_HOST"

    if is_prov_host ; then
        local rc

        rc=0
        _main "$@" || rc="$?"
        return "$rc"
    fi

    local tdir="/tmp/opilab-demo"

    _echo_p "Copy demo to provisioning host $PROV_HOST ($tdir)"
    rsync -a --info=NAME \
        --delete \
        --exclude="*.swp" \
        --exclude=".mypy_cache/" \
        --exclude="__pycache__/" \
        --exclude="kubeconfig*" \
        . \
        "root@$PROV_HOST:$tdir/" \
        ;

    local envs=()
    if [ -n "$PROV_HOST" ] ; then
        envs+=( "PROV_HOST=$PROV_HOST" )
    fi
    if [ -n "$REMOTE_KUBECONFIG" ] ; then
        envs+=( "KUBECONFIG=$REMOTE_KUBECONFIG" )
    fi
    if [ -n "$_SHOW_TIMESTAMP" ] ; then
        envs+=( "_SHOW_TIMESTAMP=$_SHOW_TIMESTAMP" )
    fi

    # shellcheck disable=SC2031
    _exec prov_host \
        /usr/bin/env \
        _ECHO_P_INDENT="$_ECHO_P_INDENT  " \
        "${envs[@]}" \
        bash "${_OPI_BASH_X[@]}" "$tdir/$SCRIPTNAME" "$@"
}

use_to_nodenames() {
    local my_use="$1"

    # Unusual, this actuall sets shell variables!!
    # The caller should predefine
    #
    #   local USE
    #   local node_dpu
    #   local node_host

    case "$my_use" in
        p|ptl)
            USE=ptl
            node_dpu='worker-dpu-ptl-243'
            node_host='worker-host-ptl-243'
            ;;
        m|marvell)
            USE=marvell
            node_dpu='worker-dpu-marvell-41'
            node_host='worker-host-marvell-41'
            ;;
        i|ipu)
            USE=ipu
            node_dpu='worker-dpu-ipu-219'
            node_host='worker-host-ipu-219'
            ;;
        *)
            return 1
            ;;
    esac
}

###############################################################################

yaml_create_nopnf_dpu_pod() {
    local USE="$USE"
    local node_dpu="$node_dpu"
    local IPADDR_PART="$IPADDR_PART"

    cat <<EOF | _unindent 8
        apiVersion: v1
        kind: Pod
        metadata:
          name: "nopnf-dpu-$USE"
          namespace: openshift-dpu-operator
          labels:
            app: nopnf-dpu
            nopnf: dpu
          annotations:
            k8s.v1.cni.cncf.io/networks: dpunfcni-conf, dpunfcni-conf
        spec:
          nodeSelector:
            kubernetes.io/hostname: "$node_dpu"
          containers:
            - name: appcntr1
              image: ghcr.io/ovn-kubernetes/kubernetes-traffic-flow-tests:latest
              command: ["/bin/bash", "-c"]
              args:
                - |
                  ip addr add 10.56.217.$IPADDR_PART/24 dev net1 && \\
                  ip addr add 172.16.3.$IPADDR_PART/24 dev net2 && \\
                  exec /usr/bin/container-entry-point.sh
              securityContext:
                privileged: true
              resources:
                requests:
                  openshift.io/dpu: "2"
                limits:
                  openshift.io/dpu: "2"
EOF
}

yaml_create_nopnf_host_pod() {
    local USE="$USE"
    local node_host="$node_host"
    local IPADDR_PART="$IPADDR_PART"

    cat <<EOF | _unindent 8
        apiVersion: v1
        kind: Pod
        metadata:
          name: "nopnf-host-$USE"
          namespace: default
          labels:
            app: nopnf-host
            nopnf: host
          annotations:
            k8s.v1.cni.cncf.io/networks: default-sriov-net
        spec:
          nodeSelector:
            kubernetes.io/hostname: "$node_host"
          containers:
            - name: appcntr1
              image: ghcr.io/ovn-kubernetes/kubernetes-traffic-flow-tests:latest
              command: ["/bin/bash", "-c"]
              args:
                - |
                  ip addr add 10.56.217.$IPADDR_PART/24 dev net1 && \\
                  ip addr add 172.16.3.$IPADDR_PART/24 dev net1 && \\
                  exec /usr/bin/container-entry-point.sh
              securityContext:
                privileged: true
              resources:
                requests:
                  openshift.io/dpu: "1"
                limits:
                  openshift.io/dpu: "1"
EOF
}


###############################################################################

aipod_containerfile() {
    cat <<'    EOF' | _unindent 8
        FROM ubuntu:latest as builder
        RUN \
            apt-get update && \
            apt-get install -y wget ca-certificates && \
            mkdir -p /models/1 && \
            wget --no-check-certificate https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.xml -O /models/1/model.xml && \
            wget --no-check-certificate https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.bin -O /models/1/model.bin

        # FROM openvino/model_server:latest
        FROM docker.io/openvino/model_server@sha256:6dc47394d55778baf63f53a41643269a01fae952bcfb0e466d4b9f7c4daa8114
        ENV OPIDEMO_VENV=/opidemo/venv
        ENV FORCE_IS_PROV_HOST=1
        ENV _DEMO_NO_OC=1
        COPY --from=builder /models/1 /models/1
        COPY . /opidemo
        USER root
        RUN \
            apt-get update && \
            apt-get install -y \
                ethtool \
                iproute2 \
                iputils-ping \
                libgl1 \
                libglib2.0-0 \
                net-tools \
                procps \
                python3-pip \
                python3-venv \
                tcpdump \
                vim && \
            bash -c 'cd /opidemo && source ./opidemo && py_activate_venv' && \
            ln -s /opidemo/opidemo /bin && \
            apt-get clean && \
            rm -rf /var/lib/apt/lists/*
        USER ovms
        CMD [ "--model_path=/models", "--model_name=resnet50", "--port=9000", "--rest_port=8000" ]
    EOF
}

# 3:extra helper:4
#
# Build our own modified resnet container and push it to
# $_OPIDEMO_AIPOD_IMAGE.  Will be used by the deployment as it requires
# no extra setup or external data download.
#
# By unsetting _OPIDEMO_AIPOD_IMAGE during redeploy we can fallback to
# using the original, upstream container directly.
do_aipod_build_container() {
    (
        set -ex
        podman build --format=docker -t "$_OPIDEMO_AIPOD_IMAGE" -f <(aipod_containerfile) .
        podman push "$_OPIDEMO_AIPOD_IMAGE"
    )
}

aipod_use_own_image() {
    if [ -n "$_OPIDEMO_AIPOD_IMAGE" ] ; then
        # With this environment variable defined (which it is by default),
        # we use our own container image from quay.io.
        #
        # If selected, is a rebuild of the ovino image. See also aipod_build_container.
        #
        # The benefit is that this image is self contained and require no additional
        # setup (nor an InitContainer)
        return 0
    fi
    return 1
}

###############################################################################

aipod_get_podnames() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _oc get -n default pods \
        -l app="aipod" \
        -o custom-columns=:metadata.name --no-headers \
        --sort-by=.metadata.name
}

aipod_detect_net1_ip() {
    local aipod_name="$1"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local rc=0
    local ip

    aipod_name="${aipod_name#pod/}"

    ip="$(
        _oc get -n default "pod/$aipod_name" \
            -o jsonpath='{.metadata.annotations.k8s\.v1\.cni\.cncf\.io/network-status}' \
            | jq -r '
                   .[]
                   | select(.interface == "net1")
                   | .ips[0]
            ' \
        )" \
        || rc=1

    if [ "$rc" -eq 0 ] && [ -n "$ip" ] ; then
        printf '%s' "$ip"
        return 0
    fi

    return 1
}

yaml_create_aipod_deployment() {
    local node_host="$node_host"

    local hostname_line=""

    if [ -n "$node_host" ] ; then
        hostname_line="
                    kubernetes.io/hostname: \"$node_host\""
    fi

    if aipod_use_own_image ; then
        cat <<EOF | _unindent 12
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: resnet50-model-server
              namespace: default
            spec:
              replicas: $NUM_PODS
              selector:
                matchLabels:
                  app2: resnet50-model-server-service
              template:
                metadata:
                  annotations:
                    k8s.v1.cni.cncf.io/networks: default-sriov-net
                  labels:
                    app2: resnet50-model-server-service
                    app: aipod
                spec:
                  securityContext:
                    runAsUser: 0
                  nodeSelector:
                    dpu.config.openshift.io/dpuside: "dpu-host"$hostname_line
                  containers:
                    - name: ovms
                      image: "$_OPIDEMO_AIPOD_IMAGE"
                      imagePullPolicy: $_OPIDEMO_IMAGE_PULL_POLICY
                      ports:
                        - containerPort: 8000
                        - containerPort: 9000
                      securityContext:
                          privileged: true
                      resources:
                        requests:
                          openshift.io/dpu: '1'
                        limits:
                          openshift.io/dpu: '1'
EOF
    else
        cat <<EOF | _unindent 12
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: resnet50-model-server
              namespace: default
            spec:
              replicas: $NUM_PODS
              selector:
                matchLabels:
                  app2: resnet50-model-server-service
              template:
                metadata:
                  annotations:
                    k8s.v1.cni.cncf.io/networks: default-sriov-net
                  labels:
                    app2: resnet50-model-server-service
                    app: aipod
                spec:
                  securityContext:
                    runAsUser: 0
                  nodeSelector:
                    dpu.config.openshift.io/dpuside: "dpu-host"$hostname_line
                  volumes:
                    - name: model-volume
                      emptyDir: {}
                  initContainers:
                    - name: model-downloader
                      image: ubuntu:latest
                      imagePullPolicy: $_OPIDEMO_IMAGE_PULL_POLICY
                      securityContext:
                        runAsUser: 0
                      command:
                        - bash
                        - -c
                        - |
                          apt-get update && \\
                          apt-get install -y wget ca-certificates && \\
                          mkdir -p /models/1 && \\
                          wget --no-check-certificate https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.xml -O /models/1/model.xml && \\
                          wget --no-check-certificate https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.bin -O /models/1/model.bin
                      volumeMounts:
                        - name: model-volume
                          mountPath: /models
                  containers:
                    - name: ovms
                      image: openvino/model_server:latest
                      imagePullPolicy: $_OPIDEMO_IMAGE_PULL_POLICY
                      args:
                        - "--model_path=/models"
                        - "--model_name=resnet50"
                        - "--port=9000"
                        - "--rest_port=8000"
                      ports:
                        - containerPort: 8000
                        - containerPort: 9000
                      volumeMounts:
                        - name: model-volume
                          mountPath: /models
                      securityContext:
                          privileged: true
                      resources:
                        requests:
                          openshift.io/dpu: '1'
                        limits:
                          openshift.io/dpu: '1'
EOF
    fi
}

aipod_create_deployment() {
    local node_host="$1"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Create/update resnet deployment \"resnet50-model-server\" in default namespace (host $(_quote "$node_host"))"

    yaml_create_aipod_deployment \
        | _oc apply -f -
}

aipod_wait_available() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _oc wait -n default "--for=jsonpath={.status.readyReplicas}=$NUM_PODS" "deployment/resnet50-model-server" --timeout=5m
}

aipod_setup_debug() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local aipod_name
    local aipod_names

    mapfile -t aipod_names < <(aipod_get_podnames)

    if aipod_use_own_image ; then
        _echo_p "resnet pods require no special setup"
        for aipod_name in "${aipod_names[@]}" ; do
            _echo_p "  show IP addresses in resnet pod $aipod_name"
            _oc -n default exec -i "pod/$aipod_name" -- /bin/bash -c '
                ip -brief addr
            ' | _indent 12
        done
        return
    fi

    for aipod_name in "${aipod_names[@]}" ; do
        _echo_p "Install tcpdump and tools in resnet pod $aipod_name"
        _oc -n default exec -i "pod/$aipod_name" -- /bin/bash -c '
            set -x &&
            apt-get -qq update &&
            apt-get -qq install -y procps iproute2 iputils-ping net-tools tcpdump ethtool &>/dev/null &&
            ip -brief addr
        '
    done
}

# 3:extra helper:5
# [POD]
# Fetch the IP address of the requested pod (pod either by name or by index).
# If POD is omitted it defaults to "1", the first pod.
do_aipod_get_ip() {
    local name="$1"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    shift || :

    if [ -z "$name" ] ; then
        name='1'
    fi

    [ "$#" -eq 0 ] || die "Invalid arguments"

    local aipod_name="$name"
    case "$name" in
        pod/*)
            ;;
        [0-9]|[0-9][0-9])
            aipod_name="$(aipod_get_podnames | sed -n "${name}p")"
            if [ -z "$aipod_name" ] ; then
                die "Could not find pod # $name"
            fi
            ;;
        *)
            aipod_name="pod/$name"
            ;;
    esac


    ip="$(aipod_detect_net1_ip "$aipod_name")" \
        || die "Cannot detect IP address for pod $name"

    _echo "$ip"
}

###############################################################################

nginx_get_podname() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local out

    out="$(_oc get pods -l app=nginx -o name)"
    if [[ "$out" =~ [[:space:]] ]] ; then
        die "Did not find exactly one nginx pod. Check \`oc get pods -l app=nginx -o name\`"
    fi
    _echo_n "$out"
}

nginx_exec() {
    local nginx_pod_name="$nginx_pod_name"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    if [ -z "$nginx_pod_name" ] ; then
        nginx_pod_name="$(nginx_get_podname)"
    fi

    _oc -n openshift-dpu-operator exec -i "$nginx_pod_name" -- "$@"
}

yaml_create_nginx_deployment() {
    local node_dpu="$node_dpu"

    local hostname_line=""

    if [ -n "$node_dpu" ] ; then
        hostname_line="
                kubernetes.io/hostname: \"$node_dpu\""
    fi

    cat <<EOF | _unindent 8
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: nginx
          namespace: openshift-dpu-operator
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: nginx
          template:
            metadata:
              labels:
                app: nginx
              annotations:
                k8s.v1.cni.cncf.io/networks: dpunfcni-conf, dpunfcni-conf
            spec:
              serviceAccountName: dpu-daemon-sa
              nodeSelector:
                dpu.config.openshift.io/dpuside: "dpu"$hostname_line
              containers:
              - name: nginx
                image: nginx
                imagePullPolicy: $_OPIDEMO_IMAGE_PULL_POLICY
                ports:
                - name: web
                  containerPort: 8080
                resources:
                  requests:
                    openshift.io/dpu: "2"
                  limits:
                    openshift.io/dpu: "2"
                securityContext:
                  privileged: true
                  capabilities:
                    drop:
                    - ALL
                    add:
                    - NET_RAW
                    - NET_ADMIN
EOF
}

nginx_create_deployment() {
    local node_dpu="$1"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Create/Update Deployment \"nginx\" in openshift-dpu-operator for NetworkFunction (host $(_quote "$node_dpu"))"

    yaml_create_nginx_deployment | \
        _oc apply -f -
}

nginx_wait_available() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _oc wait -n openshift-dpu-operator '--for=condition=Available' deployment/nginx --timeout=300s
}

_nginx_setup_base() {
    local nginx_pod_name="$nginx_pod_name"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Configure pod/nginx with base configuration"

    # Install TLS key and certificate.
    nginx_exec /bin/bash -c 'cat > /etc/nginx/server.crt' < ./server.crt
    nginx_exec /bin/bash -c 'cat > /etc/nginx/server.key' < ./server.key

    # Move conflicting default configuration.
    nginx_exec /bin/bash -c '[ ! -f /etc/nginx/conf.d/default.conf ] || mv /etc/nginx/conf.d/default.conf "/etc/nginx/conf.d/default.conf~"'

    # Install a "91-upstream.conf" configuration file. See function
    # _nginx_setup_upstream() which modifies this file.
    _nginx_setup_upstream_ip

    # Install a "90-base.conf" file for proxying requests to the model servers.
    cat <<'    EOF' | _unindent 8 | nginx_exec /bin/bash -c 'cat > /etc/nginx/conf.d/90-base.conf'
        log_format main2 '$remote_addr:$remote_port > '
                         '[$time_iso8601.$msec] "$request" '
                         '$status $body_bytes_sent "$http_referer" '
                         '"$http_user_agent" "$http_x_forwarded_for" '
                         'rt=$request_time';

        server {
            access_log /var/log/nginx/access.log main2;

            listen *:443 ssl;
            http2 on;

            server_name n1.nginx.ipu.opicluster.opiproject-lab.org;
            ssl_certificate /etc/nginx/server.crt;
            ssl_certificate_key /etc/nginx/server.key;

            # proxy gRPC → your upstream
            location / {
                # these must match your gRPC host header
                grpc_set_header   Host              $http_host;
                grpc_set_header   X-Real-IP         $remote_addr;
                grpc_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;
                grpc_pass         grpc://model_servers;
            }
            location /nginx_status {
              stub_status on;
            }
        }
    EOF

    # Install a few useful packages and configure static IP addresses
    # inside the pod.
    # - 10.56.217.200/24: IP address to talk with AI demo pods (see the
    #   default-sriov-net net-attach-def).
    # - $NGINX_IP/24: this IP address is reachable from external. HTTP
    #   requests on this address will be load balanced by the nginx proxy.
    _echo_p "Configure pod/nginx with IP addresses"
    nginx_exec bash -c "
        apt-get -qq update && \\
        apt-get -qq install -y procps iproute2 iputils-ping net-tools tcpdump ethtool &>/dev/null &&
        ethtool -K net1 rx off tx off && \\
        ethtool -K net2 rx off tx off && \\
        ip addr flush dev net1 && \\
        ip addr flush dev net2 && \\
        ip addr add 10.56.217.200/24 dev net1 && \\
        ip addr add $NGINX_IP/24 dev net2 && \\
        nginx -s reload 2>/dev/null && \\
        set -x && \\
        ip -brief addr
    "
}

_nginx_setup_upstream_ip() {
    local nginx_pod_name="$nginx_pod_name"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"
    local upstream_servers=( "$@" )

    if [ "$#" -eq 0 ] ; then
        # Add a dummy IP address. It is a problem to create a configuration
        # without servers.
        upstream_servers+=( "10.56.217.50" )
    fi
    (
        _echo "upstream model_servers {"
        _echo "    # Add \"server \$IP:9000;\" entries to pods."
        for ip in "${upstream_servers[@]}" ; do
            _echo "    server $ip:9000;"
        done
        _echo "}"
    ) \
    | nginx_exec /bin/bash -c '
        cat > /etc/nginx/conf.d/91-upstream.conf && \
        nginx -s reload 2>/dev/null
    '
}

_nginx_setup_upstream() {
    local nginx_pod_name="$nginx_pod_name"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local aipod_name
    local aipod_names
    local ip

    # Detect and configure the IP addresses of the AI pods as upstream for the
    # nginx load balancer.
    #
    # On the host side the network attachment definition default-sriov-net is
    # configured to hand out a certain 10.56.217.0/24 range to the pods.

    mapfile -t aipod_names < <(aipod_get_podnames)

    local addresses=()

    for aipod_name in "${aipod_names[@]}" ; do
        ip="$(aipod_detect_net1_ip "$aipod_name")" \
            || { _echo_p "${C_RED}ERROR${C_RESET}: Failure to detect IP address in $aipod_name"; return 1; }

        _echo_p "Configure pod/nginx with upstream IP address $ip for $aipod_name"
        addresses+=("$ip")
    done

    _nginx_setup_upstream_ip "${addresses[@]}"
}

_nginx_setup_reload() {
    local nginx_pod_name="$nginx_pod_name"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Reload pod/nginx pod"
    nginx_exec /bin/bash -c "nginx -s reload 2>/dev/null"
}

_nginx_wait_ready() {
    local PROV_HOST="$PROV_HOST"
    local _cmd_silent="$_cmd_silent"
    local _cmd_show_output="$_cmd_show_output"

    local out
    local rc

    if [ "$_cmd_silent" != 1 ] ; then
        _echo_p "Wait for nginx to respond on https://$NGINX_IP/nginx_status"
    fi

    rc=0
    out="$(
        # shellcheck disable=SC2016
        _EXEC_SILENT=1 \
        _exec prov_host \
            bash -c 'curl -f -s --cacert <(cat) "https://'"$NGINX_IP"'/nginx_status" 2>&1' \
            < "./server.crt"
    )" || rc="$?"

    if [ "$rc" -ne 0 ] ; then
        _echo_p "  ${C_RED}nginx failed to respond$C_RESET"
        _echo "$out"
        die "nginx does not reply HTTPS requests"
    fi

    if [ "$_cmd_silent" != 1 ] ; then
        _echo_p "  nginx ${C_GREEN}ready$C_RESET"
    else
        _echo "  nginx ${C_GREEN}ready$C_RESET"
    fi

    if [ "$_cmd_show_output" = 1 ] ; then
        _echo "$out" | _indent 4
    fi
}

nginx_setup() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"
    local update_only="$update_only"
    local setup_only="$setup_only"

    local nginx_pod_name

    nginx_pod_name="$(nginx_get_podname)"

    [ -n "$nginx_pod_name" ] || die "Could not find ready pod"

    # We run the unmodified nginx pod from Docker Container Registry.
    #
    # For the demo setup, we must configure it in a suitable way. Primarily the
    # nginx configuration.
    if [ "$update_only" != 1 ] ; then
        _echo_p "Setup nginx inside $nginx_pod_name"
    fi
    (
        # shellcheck disable=SC2030
        local _ECHO_P_INDENT="$_ECHO_P_INDENT  "

        if [ "$update_only" != 1 ] ; then
            _nginx_setup_base
        fi
        if [ "$setup_only" != 1 ] ; then
            _nginx_setup_upstream
        fi

        _nginx_wait_ready
    )
}

###############################################################################

py_pip_install() {
    pip install --upgrade pip
    pip install \
        black \
        flake8 \
        mypy \
        numpy \
        opencv-python \
        ovmsclient \
        ;
}

py_activate_venv() {
    local setup=0

    if declare -F deactivate 2>/dev/null ; then
        deactivate
    fi

    if [ ! -f "$OPIDEMO_VENV/bin/activate" ] ; then
        _echo_p "Create Python venv at $OPIDEMO_VENV"
        "${PYTHON:-python3}" -mvenv "$OPIDEMO_VENV"
        setup=1
    fi

    # shellcheck disable=1091
    source "$OPIDEMO_VENV/bin/activate"

    if [ "$setup" = 1 ] ; then
        _echo_p "Install Python packages in venv"
        py_pip_install
    fi
}

_detect_dpuKindForDeployment() {
    local namespace="$1"
    local name="$2"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local hostname

    hostname="$(_oc get -n "$namespace" "$name" -o jsonpath='{.spec.template.spec.nodeSelector}' 2>/dev/null \
        | jq '."kubernetes.io/hostname"' -r 2>/dev/null \
        ; true
    )"

    [ -n "$hostname" ] || return 1

    local productName

    productName="$(_oc get dpu -o json 2>/dev/null\
        | jq --arg hostname "$hostname" -r '.items | map(select(.spec.nodeName == $hostname)) | first | .spec.dpuProductName' 2>/dev/null \
        ; true
    )"

    case "$productName" in
        "Marvell DPU")
            _echo_n "marvell"
            ;;
        "Intel IPU E2100")
            _echo_n "ipu"
            ;;
        "Intel Netsec Accelerator")
            _echo_n "ptl"
            ;;
        *)
            return 1
            ;;
    esac
}

detect_deployment() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _detect_dpuKindForDeployment "openshift-dpu-operator" "deployment/nginx" \
        || true
}

unschedule() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Unschedule deployments"

    _oc -n openshift-dpu-operator scale deployment/nginx --replicas=0 || true
    _oc -n default scale "deployment/resnet50-model-server" --replicas=0 || true

    _oc wait -n openshift-dpu-operator --for=delete pod -l app=nginx --timeout=120s
    _oc wait -n default --for=delete pod -l app="aipod" --timeout=10s
}

###############################################################################

_redeploy_args() {
    local my_use="$1"
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    if [ "$#" -eq 0 ] || [ "$my_use" = 'auto' ] ; then
        my_use="$(detect_deployment)"
        if [ -z "$my_use" ] ; then
            my_use='marvell'
        fi
        shift || :
    else
        shift
    fi

    if [ "$my_use" = 'alternate' ] || [ "$my_use" = 'A' ] ; then
        my_use="$(detect_deployment)"
        if [ -z "$my_use" ] || [ "$my_use" = "ptl" ] ; then
            my_use='marvell'
        elif [ "$my_use" = "marvell" ] ; then
            my_use='ipu'
            my_use='ptl' #FIXME: when IPU works, alternate to that.
        elif [ "$my_use" = "ipu" ] ; then
            my_use='ptl'
        else
            my_use='marvell'
        fi
    fi

    # The caller should define. We will set that.
    #   local USE=
    #   local node_dpu=
    #   local node_host=
    use_to_nodenames "$my_use" \
        || return 1

    [ "$#" -eq 0 ] || return 1
}


# 1:setup:1
# [USE]
# Deploy (or update) the demo application.
#
# USE can be "ptl", "marvell" or "ipu" to deploy using the respective backend.
#
# Set USE to "auto" to reuse the current deployment (or default to "marvell").
# This is the default.
#
# Set USE to "alternate" to toggle between backends.
do_redeploy() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local USE=
    local node_dpu=
    local node_host=
    _redeploy_args "$@" \
        || die "Invalid arguments"

    unschedule

    _echo_p "Deploy for $C_BLUE$(_quote "$USE")$C_RESET"

    (
        # shellcheck disable=SC2030,SC2031
        local _ECHO_P_INDENT="$_ECHO_P_INDENT  "

        nginx_create_deployment "$node_dpu"
        aipod_create_deployment "$node_host"

        nginx_wait_available
        aipod_wait_available

        aipod_setup_debug
        nginx_setup
    )
}

# 1:setup:2
# [USE]
# Create/update the NGINX Deployment. This is a part of "redeploy"
# step. See "redeploy" for the "USE" parameter.
#
# This is basically the same as `./opidemo yaml nginx USE | oc apply -f -`
do_create_nginx_deployment() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local USE=
    local node_dpu=
    local node_host=
    _redeploy_args "$@" \
        || die "Invalid arguments"

    nginx_create_deployment "$node_dpu"
}

# 1:setup:3
# [USE]
# Create/update the resnet pod Deployment. This is a part of "redeploy"
# step. See "redeploy" for the "USE" parameter.
#
# This is basically the same as `./opidemo yaml aipod USE | oc apply -f -`
do_create_aipod_deployment() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    local USE=
    local node_dpu=
    local node_host=
    _redeploy_args "$@" \
        || die "Invalid arguments"

    aipod_create_deployment "$node_host"
}

# 1:setup:4
#
# Install debugging packages in aipods. This is a subset of "redeploy".  When
# using image from quay.io (the default, see $_OPIDEMO_AIPOD_IMAGE) then
# this does nothing useful. When using the original ovino container, it installs
# tcpdump and other packages useful for debugging.
do_aipod_setup_debug() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    aipod_setup_debug
}

# 1:setup:5
#
# Setup the nginx pod. This is necessary after the pod starts, because
# we run a "nginx" pod from Dockerhub. We must configure nginx in it.
# This is a subset of "redeploy"
#
# You still need "nginx_update_ips" afterwards.
do_nginx_setup() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    setup_only=1 \
    nginx_setup
}

# 1:setup:6
#
# Reconfigure NGINX pod with IP addresses of resnet pods.
# This is a subset of "nginx_setup". You need to run this when
# new pods are started.
do_nginx_update_ips() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Update IP addresses in NGINX pod"

    update_only=1 \
    nginx_setup
}

# 1:setup:7
#
# Delete the demo deployment.
do_undeploy() {
    local KUBECONFIG="$KUBECONFIG"
    local OC_REMOTE="$OC_REMOTE"
    local PROV_HOST="$PROV_HOST"

    _echo_p "Undeploy"

    _oc delete -n openshift-dpu-operator deployment/nginx || true
    _oc delete -n default "deployment/resnet50-model-server" || true
}

# 2:demo:6
#
# Test the nginx load balancer by asking the resnet pods to classify images
# of animals. This is the demo usage.
do_predict() {
    local PROV_HOST="$PROV_HOST"
    local _DEMO_NO_OC="$_DEMO_NO_OC"

    if ! is_prov_host ; then
        # The nginx IP is only accessible from tgen1. Remote the call.
        call_remote predict
        return 0
    fi

    py_activate_venv

    local use=
    if [ "$_DEMO_NO_OC" != 1 ] ; then
        use="$(detect_deployment)"
        if [ -z "$use" ] ; then
            _echo_p "${C_YELLOW}No deployment detected$C_RESET"
        else
            use=" (use $C_BLUE$use$C_RESET)"
        fi
    fi

    _echo_p "${C_GREEN}PREDICT IMAGES$C_RESET$use..."

    local rc

    rc=0
    ./predict_images/run.py ./predict_images/images/ || rc=1

    deactivate

    [ "$rc" -eq 0 ] || die "Failed to call predict demo application. Is NGINX pod at https://$NGINX_IP working?"
}

_prompt() {
    local prompt="$prompt"

    if [ "$prompt" = "clear" ] ; then
        local rows
        rows="$(tput lines)"
        tput cup "$((rows - 1))" 0
    fi
    if [ "$prompt" = "prompt" ] || [ "$prompt" = "clear" ] ; then
        _echo_n "Press [ENTER] to continue"
        read -r
        tput cuu1 && tput el
    fi
    if [ "$prompt" = "clear" ] ; then
        clear
    else
        _echo
    fi
}

_echo_inspect() {
    _echo "$C_RED$C_BG_BRIGHT_CYAN### $*$C_RESET"
}

_oc_inspect() {
    oc_verbose=1 \
    _oc "$@"
}

# 2:demo:7
# [prompt|clear]
# Inspect the created setup. Pass "prompt" to stop between commands.
# Pass "clear" to prompt and clear the screen for each command.
do_inspect() {
    local prompt=""

    if [ "$#" -gt 0 ] ; then
        case "$1" in
            p|prompt)
                prompt=prompt
                shift
                ;;
            c|clear)
                prompt=clear
                shift
                ;;
            *)
                die "Invalid argument"
                ;;
        esac
    fi

    [ "$#" -eq 0 ] || die "Invalid arguments"

    if [ "$prompt" = 'clear' ] ; then
        clear
    fi

    _echo_inspect "See the DPUs and the Nodes in the OCP cluster"
    _oc_inspect get node
    _oc_inspect get dpu

    _prompt

    _echo_inspect "See the dpu-operator's operands"
    _oc_inspect get -n openshift-dpu-operator pod -o wide\
        | grep -v '^nginx-'

    _prompt

    _echo_inspect "The NGINX pod is a common Deployment"
    do_yaml "nginx" "\$DPU_HOST"

    _prompt

    _echo_inspect "The NGINX Network Function pod"
    _oc_inspect get -n openshift-dpu-operator deployment/nginx
    _oc_inspect get -n openshift-dpu-operator pod -l app=nginx -o wide

    _prompt

    _echo_inspect "The client pod are created via a common Deployment"
    do_yaml "aipod" "\$WORKER_NODE"

    _prompt

    _echo_inspect "The client pods started by the deployment"
    _oc_inspect get -n default deployment
    _oc_inspect get -n default pod -l 'app=aipod' -o wide

    _prompt

    _echo_inspect "When pods start, we must update the NGINX pod"
    do_nginx_update_ips

    _prompt

    _echo_inspect "The NGINX pod on the DPU answers at https://$NGINX_IP/nginx_status"
    _cmd_silent=1 \
    _cmd_show_output=1 \
    _nginx_wait_ready

    _prompt

    _echo_inspect "Run AI classifcation demo through NGINX loadbalancer"
    (
        # shellcheck disable=SC2031
        local _ECHO_P_INDENT="$_ECHO_P_INDENT  "

        do_predict
    )
}

# 3:extra helper:1
# OC_ARGS...
# Run `oc $OC_ARGS`.
do_oc() {
    _oc "$@"
}

# 3:extra helper:2
# ARGS...
# Execute the script on PROV_HOST with the provided arguments.
do_remote() {
    call_remote "$@"
}

# 3:extra helper:3
# WHAT [HOST]
# We configure workloads using standard Deployments. This shows the YAML for
# such a deployment. You could apply this with `oc apply -f -`.
#
# WHAT can be "nginx" for the deployment of the NGINX Network Function or "aipod"
# for the deployment of the AI pods.
#
# The optional HOST parameter determines the node selector for the host.  If
# empty, it means to not set the nodeSelector. If set to "ptl", "marvell" or
# "ipu", it uses the well known host names in our cluster setup. Any other
# value is taken as literal hostname.
do_yaml() {
    local WHAT="$1"
    local HOST="$2"

    local yaml_create

    local IPADDR_PART=
    local USE=""
    local node_dpu=""
    local node_host=""
    local has_host=1
    local host_array
    if [ "$#" -ge 2 ] ; then
        host_array+=("$HOST")
    fi
    _redeploy_args "${host_array[@]}" \
        || has_host=0


    case "$WHAT" in
        nginx)
            yaml_create=yaml_create_nginx_deployment
            if [ "$has_host" = 0 ] ; then
                node_dpu="$HOST"
            fi
            ;;
        aipod)
            yaml_create=yaml_create_aipod_deployment
            if [ "$has_host" = 0 ] ; then
                node_host="$HOST"
            fi
            ;;
        nopnf-dpu)
            yaml_create=yaml_create_nopnf_dpu_pod
            if [ "$has_host" = 0 ] ; then
                node_dpu="$HOST"
            fi
            case "$USE" in
                'marvell')
                    IPADDR_PART=11
                    ;;
                'ptl')
                    IPADDR_PART=12
                    ;;
                *)
                    die "Creating a YAML for $WHAT requires a valid \$USE. But got $(_quote "$USE")"
                    ;;
            esac
            ;;
        nopnf-host)
            yaml_create=yaml_create_nopnf_host_pod
            if [ "$has_host" = 0 ] ; then
                node_host="$HOST"
            fi
            case "$USE" in
                'marvell')
                    IPADDR_PART=21
                    ;;
                'ptl')
                    IPADDR_PART=22
                    ;;
                *)
                    die "Creating a YAML for $WHAT requires a valid \$USE. But got $(_quote "$USE")"
                    ;;
            esac
            ;;
        *)
            [ "$#" -gt 0 ] || die "Missing WHAT argument. Must be 'nginx' or 'aipod'"
            die "Invalid WHAT argument. Must be 'nginx' or 'aipod'"
            ;;
    esac

    shift || :
    shift || :

    [ "$#" -eq 0 ] || die "Invalid arguments"

    "$yaml_create" \
        | _yq_pretty
}

# 4:extra helper:8
#
# Run shellcheck, black and mypy on the sources of the demo script.
do_check() {
    _echo_p "Validate script via shellcheck"
    shellcheck "$SCRIPTNAME"
    shellcheck "./demo.sh"
    shellcheck "./inspect.sh"

    py_activate_venv

    _echo_p "Format python sources with black"
    if ! black --check . ; then
        black .
        die "Python sources were not correctly formatted with black."
    fi

    _echo_p "Check python sources with mypy"
    mypy

    deactivate

    _echo_p "Check usage command"
    usage 1>/dev/null
}

###############################################################################

_with_pod() {
    local what="$1"
    local POD_PATTERNS=( "${POD_PATTERNS[@]}" )
    local aliases

    local pattern

    if [ "${#POD_PATTERNS[@]}" -eq 0 ] ; then
        return 0
    fi

    aliases=( "$what" "${what#pod/}" )

    if [[ "$what" == pod/resnet50-model-server* ]] ; then
        aliases+=( aipod aipods )
    fi

    if [[ "$what" == pod/nginx* ]] ; then
        aliases+=( nginx pod/nginx )
    fi

    for pattern in "${POD_PATTERNS[@]}" ; do
        local alia
        for alia in "${aliases[@]}" ; do
            # shellcheck disable=SC2053
            if [[ "$alia" == $pattern ]] ; then
                return 0
            fi
        done
    done

    return 1
}

_show_pod() {
    local namespace="$1"
    local name="$2"
    local ip="$3"
    local status="$4"
    local HEADER="$HEADER"
    local POD_PATTERNS=( "${POD_PATTERNS[@]}" )
    local name_for_withcheck
    local name_for_display
    local name_for_statuscheck

    name_for_withcheck="$name"
    name_for_display="$name"
    name_for_statuscheck="$name"

    if [ "$name" = nginx ] ; then
        local name2
        local rc

        rc=0
        name2="$(nginx_get_podname 2>&1)" || rc=1

        if [ "$rc" -eq 0 ] && [ -n "$name2" ] ; then
            name_for_withcheck="$name2"
            name_for_display="$name2"
            status="UP"
        else
            name_for_withcheck="pod/nginx"
            name_for_display="pod/nginx*"
            status="DOWN"
        fi
    fi

    if [ "$HEADER" != 1 ] && ! _with_pod "$name_for_withcheck" ; then
        return 0
    fi

    if [ -z "$status" ] ; then
        if _oc get -n "$namespace" "$name_for_statuscheck" &>/dev/null ; then
            status="UP"
        else
            status="DOWN"
        fi
    fi

    if [ "$HEADER" = 1 ] ; then
        :
    elif [ "$status" = UP ] ; then
        status="$C_GREEN$status$C_RESET"
    else
        status="$C_RED$status$C_RESET"
    fi

    if [ "$HEADER" != 1 ] ; then
        printf "$C_BLUE"
    fi

    printf "%-23s %-43s %-27s %-10s$C_RESET\n" \
        "$namespace" \
        "$name_for_display" \
        "$ip" \
        "$status"
}

# 4:extra helper:7
# [PODS...]
# Show table with pods and IP addresses. Accepts pattern for podnames, like
# "resnet*"
do_pods() {
    local pod_name
    local POD_PATTERNS=( "$@" )

    HEADER=1 _show_pod NAMESPACE NAME IP STATUS

    _show_pod "-"                    external               "10.56.217.1   172.16.3.1"   "UP"
    _show_pod openshift-dpu-operator nginx                  "10.56.217.200 172.16.3.200" ""
    _show_pod openshift-dpu-operator pod/nopnf-dpu-marvell  "10.56.217.11  172.16.3.11"  ""
    _show_pod openshift-dpu-operator pod/nopnf-dpu-ptl      "10.56.217.12  172.16.3.12"  ""
    _show_pod default                pod/nopnf-host-marvell "10.56.217.21  172.16.3.21"  ""
    _show_pod default                pod/nopnf-host-ptl     "10.56.217.22  172.16.3.22"  ""

    mapfile -t aipod_names < <(aipod_get_podnames)
    for pod_name in "${aipod_names[@]}" ; do
        _show_pod default "pod/$pod_name" "$(aipod_detect_net1_ip "$pod_name")" "UP"
    done
    if [ "${#aipod_names[@]}" -eq 0 ] ; then
        _show_pod default "pod/resnet50-model-server*" "" "DOWN"
    fi
}

###############################################################################

# 4:extra helper:5
#
# Regenerate ./live-demo directory with file, script and readme to go through the
# live demo.
do_generate_live_demo() {
    _echo_p "Start generating $C_GREEN$(_quote "$PWD/live-demo/")$C_RESET ..."
    if [ -d "./live-demo" ] ; then
        mv ./live-demo "/tmp/opidemo-live-demo-backup-$(date '+%Y%m%d-%H%M%S')"
    fi
    mkdir -p ./live-demo

    mkdir ./live-demo/0.before
    (
        cd ./live-demo/0.before
        cat <<'        EOF' | _generate_notes
            - run demo on root@wsfd-advnetlab227.anl.eng.bos2.dc.redhat.com
              in "/root/opi-poc/demos/Secure-AI-inferencing-NGINX-IPU/demo/live-demo" directory.

            - "opidemo" is in your PATH and system lab227 is generally setup
              so that everything works out of the box.

            - `opidemo index` gives the outline (files to run). Have this present
              and follow along these files. I suggest to just run the command
              one after the other (and talk about it). But you can also type
              out (copy+paste) what the scripts do.

            - do not modify files in "live-demo". This directory is generated by
              `opidemo generate_live_demo`.

            - find "Y" in your path. It can colorize an pagerize YAML. E.g.
              `oc get node -o yaml | Y`

            - "oc" in your path is "/root/.local/bin/oc", a symlink to kubecolor.
              Find original `oc` in /usr/local/bin/oc or as `Oc` in your PATH.
              You may need that for example like `Oc project something`.

            - run `opidemo` (without arguments) to see available commands.
              Familiarize yourself with that commands are available and test
              them. It is useful to understand what they do, and that you have
              those helpers.

            - run "9.cleanup-all.sh" to get to a undeployed system. Run
              `opidemo redeploy` will setup the system again.

            - all Deployment/Pod resources in the demo tie the pod via
              nodeSelector to a certain host. Be aware of that, for example,
              "1a.nopnf-pod-marvell.yaml" and "1a.nginx-deployment-marvell.yaml"
              both will want to run on "worker-dpu-marvell-41", and that
              cannot work at the same time (too few "openshift.io/dpu" devices).
              But there is no problem to run one NF (either NGINX or nopnf)
              on one DPU and another on the other. Due to the nodeSelector this
              is easier to reason about.

            - Except are the resnet ai pod Deployment in the live-demo in
              "2.aipods-create/1.aipod-deployment.yaml" have *no* nodeSelector pods.

            - In general, AI Pods, NGINX pods and nopnf pods work from any host
              against any other host (that are connected to the DPU network).
              Regardless, we usually choose to restrict all Deployment/Pod to a certain host,
              except the aipods during live-demo.

            - On the host side, we always create "nopnf-host" pods. It can
              be there for the entire demo. You may ignore them, but if you need a
              pod on the host that is up and usable for showing something, this
              is it (`oc get -n default pod -l nopnf`).

            - Familiarize youself with the IP addresses involved. There is the
              10.56.217.0/24 subnet and the 172.16.3.0/24. NGINX and nopnf pods
              have fixes addresses.

            - Familiarize youself with the pod labels: app={nginx,aipod,nopnf-host,nopnf-dpu}.
              Also, `oc get pod -l nopnf -A` and `oc get pod -l nopnf={host,dpu} -A`.

            - Before demo, start with "9.START.sh"

            - the host pods run in "default" namespace, and the DPU operator and
              DPU pods in "openshift-dpu-operator". Your "oc" will be initialized
              with "openshift-dpu-operator", so you don't need "-n" for accessing
              those, but you will need "-n default".
        EOF

        do_yaml nopnf-host marvell | _generate_file '1a.nopnf-host-marvell.yaml' 0
        do_yaml nopnf-host ptl     | _generate_file '1b.nopnf-host-ptl.yaml' 0

        cat <<'        EOF' | _generate_bash '2.basic-initialize.sh'
            # `oc` symlinks to `kubecolor`, which doesn't support `project` command.
            /usr/local/bin/oc project openshift-dpu-operator
        EOF

        cat <<'        EOF' | _generate_bash '3.nopnf-host-create.sh'
            oc delete -n default pod -l app=nopnf-host

            oc apply -f 1a.nopnf-host-marvell.yaml
            oc apply -f 1b.nopnf-host-ptl.yaml

            sleep 1
            oc get pod -A -l nopnf -o wide
        EOF

        cat <<'        EOF' | _generate_bash '9.START.sh'
            ./9.cleanup-all.sh
            ./2.basic-initialize.sh
            ./3.nopnf-host-create.sh
        EOF

        cat <<'        EOF' | _generate_bash '9.cleanup-all.sh'
            opidemo undeploy
            oc delete -n openshift-dpu-operator pod -l app=nopnf-dpu
            oc delete -n default pod -l app=nopnf-host
        EOF
    )

    mkdir ./live-demo/1.intro-cluster
    (
        cd ./live-demo/1.intro-cluster
        cat <<'        EOF' | _generate_notes
        EOF

        cat <<'        EOF' | _generate_bash '1.show-cluster.sh'
            oc get node
            oc get dpu
        EOF

        cat <<'        EOF' | _generate_bash '2.dpu-operator.sh'
            oc get -n openshift-dpu-operator pod --field-selector status.phase=Running
        EOF
    )

    mkdir ./live-demo/2.aipods-create
    (
        cd ./live-demo/2.aipods-create
        cat <<'        EOF' | _generate_notes
            - the aipods run an image from our quay.io, built by us.
              Please understand how that image was built, see "aipod_containerfile()"
              function. There is nothing "propritary" there, we just pre-configure
              them a bit.
        EOF

        do_yaml "aipod" "" | _generate_file '1.aipod-deployment.yaml' 0

        cat <<'        EOF' | _generate_bash '2.oc-apply-aipod-deployment-yaml.sh'
            oc apply -f 1.aipod-deployment.yaml

            sleep 1

            oc get -n default deployment

            oc get -n default pod -l app=aipod -o wide
        EOF
    )

    mkdir ./live-demo/3.nopnf
    (
        cd ./live-demo/3.nopnf
        cat <<'        EOF' | _generate_notes
            - Create NF pods on the DPU. They do nothing, but we can access them
              and show that we can ping various other sides.

            - Note that resnet pods only have 10.56.217.0/24 addresses. So, they
              can ping the provisioning host at 172.16.3.1 via the default route
              on their primary network.
              However, if you were to configure a 172.16.3.0/24 address on the
              secondary network, they could reach the provisiong host that way.
              The secondary network is switched together all throughout and with
              the provisiong host.

            - note the nopnf pods are also Network Functions. They consume
              2 "openshift.io/dpu" resources. Since PTL and Marvell nodes (on the
              DPU side) in total only have 2 such resources, you can only start
              one of these pods or NGINX NF, never both. In other words, if you
              want to run NGINX NF, you must first delete the nopnf pod on the
              same DPU.

            - Here we create "app=nopnf-dpu" pods (NFs on the DPU). We can use
              them to show they can ping each other, can ping the provisiong host
              172.16.3.1 (external), and can ping the resnet aipods (created in
              the previous step). The resenet aipods have no fixed IP address,
              which makes it cumbersome.

            - Alternatively, there are also the "app=nopnf-host" pods. Those
              have stable IP addresses. You probably don't want to ever
              mention or show them. But if you do, there is a running pod
              on the host, which you could show as an example how pods can
              reach each other. Of course, if you do that, you need to explain
              yet another kind of pod, so maybe don't even go there and only
              try to ping the resnet aipods (after you determine their IP
              address).
        EOF

        do_yaml nopnf-dpu marvell | _generate_file '1a.nopnf-dpu-marvell.yaml' 0
        do_yaml nopnf-dpu ptl     | _generate_file '1b.nopnf-dpu-ptl.yaml' 0

        cat <<'        EOF' | _generate_bash '2.oc-apply-nopnf-pods.sh'
            git diff --no-index -- 1?.nopnf-dpu-*.yaml

            oc apply -f 1a.nopnf-dpu-marvell.yaml
            oc apply -f 1b.nopnf-dpu-ptl.yaml

            sleep 1
            oc get -n openshift-dpu-operator pod -l app=nopnf-dpu
        EOF

        cat <<'        EOF' | _generate_bash '3.inspect-ipaddr.sh'
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-marvell -- ip -brief addr
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-ptl     -- ip -brief addr
        EOF

        cat <<'        EOF' | _generate_bash '4.ping-nf.sh'
            opidemo pods external nopnf-dpu*
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-marvell -- ping -c3 172.16.3.12
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-marvell -- ping -c3 172.16.3.1
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-ptl     -- ping -c3 172.16.3.11
        EOF

        cat <<'        EOF' | _generate_bash '5.ping-aipod.sh'
            AIPOD1=$(oc get -n default pod -l app=aipod -o NAME | head -n1)

            opidemo pods "$AIPOD1" nopnf-dpu*

            oc exec -n default -ti "$AIPOD1" -- ip -brief addr
            oc exec -n default -ti "$AIPOD1" -- ping -c3 10.56.217.11

            AIPOD1_IP=$(opidemo aipod_get_ip "$AIPOD1")
            oc exec -n openshift-dpu-operator -ti pod/nopnf-dpu-ptl     -- ping -c3 "$AIPOD1_IP"
        EOF

        cat <<'        EOF' | _generate_bash '9.cleanup.sh'
            oc delete -n openshift-dpu-operator pod -l app=nopnf-dpu
        EOF
    )

    mkdir ./live-demo/4.nginx-deploy-nf
    (
        cd ./live-demo/4.nginx-deploy-nf
        cat <<'        EOF' | _generate_notes
            - Now we create the NGINX network function on the DPU.
            - `opidemo nginx_setup` enters the NGINX pod and configures
              nginx (e.g. IP addresses, TLS cert, nginx.conf). This is necessary
              because we use unmodified nginx container image. In a production
              environment, we would instead build our own image with this
              configuration.
            - `opidemo nginx_update_ips` gets IP addresses from AI pods, enters
              the nginx pod and configures nginx.conf. In a production environment
              some operator (automatism) would do this whenver a client pod starts.
        EOF

        do_yaml nginx marvell | _generate_file '1a.nginx-deployment-marvell.yaml' 0
        do_yaml nginx ptl | _generate_file '1a.nginx-deployment-ptl.yaml' 0

        cat <<'        EOF' | _generate_bash '2.nginx-setup.sh'
            git diff --no-index -- 1?.nginx-deployment-*.yaml

            oc apply -f 1a.nginx-deployment-marvell.yaml

            sleep 1

            oc get -n openshift-dpu-operator deployment/nginx
            oc get -n openshift-dpu-operator pod -l app=nginx

            oc wait -n openshift-dpu-operator --for=condition=Ready pod -l app=nginx

            opidemo nginx_setup
        EOF

        cat <<'        EOF' | _generate_bash '3.nginx-update-ips.sh'
            opidemo nginx_update_ips
        EOF
    )

    mkdir ./live-demo/5.run-demo
    (
        cd ./live-demo/5.run-demo
        cat <<'        EOF' | _generate_notes
            - Show the "AI" demo where the external client from the secondary
              network (172.16.3.0/24) makes request against NGINX loadbalancer
              on https://172.16.3.200. The TLS request is terminated and forwarded
              to the AI pods on the corresponding host.
        EOF

        cat <<'        EOF' | _generate_bash '1.predict.sh'
            opidemo predict
        EOF

        cat <<'        EOF' | _generate_bash '2.predict-from-pod.sh'
            AIPOD1=$(oc get -n default pod -l app=aipod -o NAME | head -n1)
            oc exec -n default -ti "$AIPOD1" -- opidemo predict
        EOF
    )

    _echo
    _echo_p "Generated:"
    do_index
}

# 4:extra helper:6
#
# Show list of files produced by "generate_live_demo". This is your outline!
do_index() {
    local dir

    if [ ! -d "./live-demo/" ] ; then
        die "live-demo directory does not exist. Run \`$SCRIPTNAME generate_live_demo\`?"
    fi

    if [ "$(realpath "./live-demo")" = "$(realpath "$ORIGINAL_PWD")" ] ; then
        cd "$ORIGINAL_PWD"
        dir=.
    else
        dir=./live-demo/
    fi

    find "$dir" '!' -type d \
        | sed 's/^\.\///' \
        | xargs -d '\n' ls --color=always \
        | GREP_COLORS='mt=01;33' grep --color=always '^\|.*\.yaml$' \
        | _indent 4 \
        | sed '/\/0\.notes\.md/i
'
}

###############################################################################

_main() {
    local main_cmd="$1"
    shift || true

    # For convenience, accept the following aliases:
    case "$main_cmd" in
        'predict_images'|predict_images/)
            main_cmd='predict'
            ;;
        'inspect.sh')
            main_cmd='inspect'
            ;;
    esac

    case "$main_cmd" in
        aipod_build_container | \
        aipod_setup_debug | \
        check | \
        generate_live_demo | \
        index | \
        nginx_setup | \
        nginx_update_ips | \
        predict | \
        undeploy \
        )
            [ "$#" -eq 0 ] || die "Invalid arguments"
            "do_$main_cmd"
            ;;
        aipod_get_ip | \
        create_aipod_deployment | \
        create_nginx_deployment | \
        inspect | \
        oc | \
        pods | \
        redeploy | \
        remote | \
        yaml \
        )
            "do_$main_cmd" "$@"
            ;;
        "")
            usage
            die "Missing command"
            ;;
        *)
            usage
            die "Unknown command '$main_cmd'"
            ;;
    esac
}

###############################################################################

##########################
# USER CONFIGURATION:
##########################
PROV_HOST="${PROV_HOST:-wsfd-advnetlab227.anl.eng.bos2.dc.redhat.com}"
OC_REMOTE="${OC_REMOTE:-0}"
KUBECONFIG="${KUBECONFIG:-$(_find_kubeconfig)}"
REMOTE_KUBECONFIG="${REMOTE_KUBECONFIG:-/root/kubeconfig.ocpcluster}"

# Also configurable, but usually not necessary.
FORCE_IS_PROV_HOST="${FORCE_IS_PROV_HOST:-0}"
_OPIDEMO_YQ_BINARY="${_DEMO_YQ_BINARY:-}"
_OPIDEMO_AIPOD_IMAGE="${_OPIDEMO_AIPOD_IMAGE:-quay.io/thaller/opidemo25:aipod}"
_OPIDEMO_IMAGE_PULL_POLICY="${_OPIDEMO_IMAGE_PULL_POLICY:-IfNotPresent}"
NUM_PODS="${NUM_PODS:-5}"
OPIDEMO_VENV="${OPIDEMO_VENV:-/tmp/opidemo-venv}"
_DEMO_NO_OC="${_DEMO_NO_OC:-0}"
##########################

ORIGINAL_PWD="$PWD"

if [[ "${BASH_SOURCE[0]}" != "$0" ]]; then
    # Sourced. We are done
    SCRIPTNAME="${BASH_SOURCE[0]}"
    die() { _echo "$C_RED$*$C_RESET" ; }
    return 0
fi

SCRIPT_PATH="$0"
case "$SCRIPT_PATH" in
  /* | */*)
     ;;
  *)
      SCRIPT_PATH="$(command -v -- "$SCRIPT_PATH")"
      ;;
esac

if [ -L "$SCRIPT_PATH" ] ; then
    SCRIPTNAME_FULL="$(realpath "$SCRIPT_PATH")"
else
    SCRIPTNAME_FULL="$SCRIPT_PATH"
fi

SCRIPTNAME_PRETTY="$(basename "$0")"
cd "$(dirname "$SCRIPTNAME_FULL")"
SCRIPTNAME="$(basename "$SCRIPTNAME_FULL")"

set -eo pipefail
shopt -s inherit_errexit

_main "$@"
